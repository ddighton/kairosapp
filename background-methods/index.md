---
layout: page
title: Background and Methods
description: ""
image:
  feature: abstract-10.jpg
  credit: dargadgetz
  creditlink: http://www.dargadgetz.com/ios-7-abstract-wallpaper-pack-for-iphone-5-and-ipod-touch-retina/
  
---
## Infrastructure: The Inventive Possibilities of Arrangement

Recent work by digital rhetoric and writing studies scholars demonstrates growing engagement with what Douglas Eyman (2016) maps as one of the emerging directions in digital rhetoric: a socio-cultural and technological engagement with infrastructure, including “the [often blackboxed] software tools that allow nearly anyone to expertly remix content across multiple modes and media” (p. 29). Key to Eyman’s definition of infrastructure is an understanding and fluency with the ways different kinds of technologies work and the social and institutional knowledge of the infrastructures in which these technologies are housed and employed. Rhetorical concerns with infrastructure have manifested in multiple special issues in digital rhetoric journals, like Present Tense’s special issue on the [Rhetoric of Platforms](https://www.presenttensejournal.org/news/special-issue-cfp/), which argues that theorizing and practicing digital rhetoric is inseparable from considerations of infrastructure, or “a meeting point of hardware, software, and culture” (Present Tense, Platform CFP). Such research points to the way in which digital infrastructures create unique and constantly shifting constraints and possibilities for composition and agency. As Jim Ridolfo and Danielle Nicole DeVoss (2009) argue, the infrastructure of Web 2.0 allows for the rhetorical velocity of texts and necessitates a digital update to the canon of delivery. John Gallagher (2017) reveals how the infrastructural layer of algorithms creates new media audiences that participate in the remix and remediation of digital texts and data. Within the growing body of writing studies literature focusing on infrastructure, the shape data and visualization take is not controlled solely by the researcher, nor is agency enacted solely by users, but co-constructed by the technologies and multiple situated contexts that become involved in communication and analytic technologies.

When theorizing the digital, arrangement can be difficult to locate beneath the architectural layers of data analytic software, but arrangement is one of the “conditions of possibility for the kind of pattern and relationship analysis carried out under the umbrella of data mining” (Brooke, qtd. in Eyman 2015, n.p.). As Brooke stretches arrangement beyond the discursive to include digital pattern finding, so arrangement also includes “manipulating digital media as well as selecting ready-made works and reconstituting them into new works; remixing” (Eyman, 2015, n.p.). As Aaron Beveridge (2017) points out, data visualization is always rhetorical, often on many levels, some computational and/or non-human. I argue for a rhetorical and feminist methodological approach to data analysis and visualization that deepens data viz’s critical possibilities and conclusions, even within hard-coded software, to expand the possibilities for visualizations and interpretations, rather than narrowing data analysis conclusions to grasp toward a truth value (boyd, 2013). 

Not only are these technologies active players in our digital research practices and the meaning communicated, but Kevin Brock and Ashley Rose Mehlenbacher (2017) argue that “code might produce and reproduce certain norms, values, and social actions” (p. 2). These same authors also argue that “the ‘digital,’ as a collection of computational machines and the logics and experiences involved in using them, remains obscured for many” (p. 5). The issue of access is deeply tied to technological and social infrastructures, as Aaron Beveridge (2018) argues by identifying several barriers for rhetoric and writing studies’ engagement with data analytics and literacy, especially involving social media data. Equally as important as physical access, Beveridge emphasizes the importance of access to “current research methodologies” for the study of large data sets often generated through streaming APIs like Twitter’s. Although scholars Laurie Gries and Aaron Beveridge are both advocates of creating data analysis and visualization tools especially for the specific research needs of those in rhetoric and writing studies, and indeed both have projects underway to do just that, existing tools provide opportunities for rhetoric and writing studies to develop such methodologies. Gaining experience with data analysis and visualization technologies will allow us to push against their affordances and perhaps contribute insight into the ways in which future tools might be designed in a more just and rhetorically-informed ways.	

## Rhetoric as it Happens: Calling the Twitter API

To work with data visualization tools like those I employ in this webtext, it’s often necessary to begin by building a database. In Lingua Fracta, Collin Brooke (2009) confronts Lev Manovich’s claim that “database and narrative are natural enemies” (Manovich, quoted in Brooke, p. 97). In Brooke’s reading of Manovich, this binary relationship comes down to the sequential organization of narrative: a narrative is structured by a sequence of unfolding events and the subsequent actions of characters. Because a database doesn’t adopt a sequential structure, a sense of time passing through lived experience, this happens and then this happens, in Manovich’s view, it cannot be a narrative. A database, of course, is structured in rows and columns and populated by individual items and modes of analysis often involve counting seeming equally weighted individual datums. By focusing on sequential order, Brooke argues that Manovich is missing a key reconfiguring of the canon of arrangement in the digital age: instead of sequential organization of events that represent time progressing, in digital media, arrangement is rhetorically configured by the user’s or researcher’s practice, both the choices and the tools s/he employs. Brooke further elaborates: “building a database of related items allows patterns and relationships to emerge” (p. 107). It is pattern, rather than sequence that defines arrangement in the database structure that allows for many digital media expressions. Although writing nearly ten years ago and before our present “big data” era, Brooke’s emphasis on pattern finding is equally relevant today. Large datasets necessitate computational modes of reading--analytics and visualizations--processes that rope in other software structures and logics before they generate something easily read by human eyes, a bar chart or line graph, for instance. These visualizations are often born from databases that structure data. Once in database form, subsequent computational methods can, indeed, read the data in way that will generate analytical results, often as visualizations. In dissecting Manovich’s claim that “database and narrative are natural enemies,” Brooke does not quite make the point that these patterns and relationships can be understood as narratives, and narratives, as Walter Fisher (1984) elucidated are “public, moral arguments” (p. 12). Indeed, in the digital era, academic programs and corporate jobs are increasingly created around “data storytelling.” Forbes argues that data storytelling skills and literacies are increasingly valuable in and that “data storytelling is a structured approach for communicating data insights, and it involves a combination of three key elements: data, visuals, and narrative” (para. 4). Although often the data storytelling model is geared towards the interests of business--the data is compiled and analyzed to increase a company’s reach and profits and limit its vulnerabilities losses--data storytelling can be a means by which rhetoric, writing studies, and technical communication expand our respective research and pedagogical practices in a way that also reflects and enriches broader understandings of data visualization, particularly its constructed and rhetorical qualities. 

Twitter’s API has several access levels, the most robust of which involve paying a subscription fee. By using the free access level, researchers can collect a sample of tweets in real time, or up to seven days in the past. Because of this time constraint, researchers have to begin collecting either as an event has already begun to unfold, or they have to choose a topic or phenomena that they expect will have ongoing interest and activity. When I set up SFM in February 2016, it wasn’t in response to a specific event or existing hashtag campaign, but more from the desire to understand how the conversation about gentrification developed on Twitter  over a sustained period of time, both locally and globally. Once SFM is installed, and Twitter grants the researcher an access token, SFM will continue to collect according to Twitter’s API restrictions, which means it can send up to fifteen requests for data every fifteen minutes per access token. Because SFM is ongoing, it allows for collection in realtime and over an extended period of time, in my case two years; however, historical data that goes back more than seven days isn’t available without a fee. Although this is a significant constraint that largely prevents unfunded researchers from collecting Twitter data around an event or time period that has passed, as William Wolff 92015) points out, social media APIs like Twitter’s does allow for an in situ study of rhetoric. 

Although in situ commonly refers to something in a fixed, original place and time, in situ more accurately examines rhetoric “as it happens” (Endres, D., Hess, A., Senda-Cook, S., & Middleton, M. K., 2016, p. 516). Endres et al (2016) use the concept of in situ to describe a a critical and participatory methodology that “provides a means to account for the rhetoric of the everyday, to locate rhetoric in relationship to broader cultural discourses, and to open space for critics to analyze, participate with, and contribute to an emancipatory form of critique” (xiv). The authors argue that this participatory approach has deep roots in rhetorical criticism wherein a researcher’s particular perspective and relationship to the political and social issues at hand are explicitly involved in the resulting critical product and meaning made. Endres et al. observe that rhetoric is currently undergoing a participatory turn, which they emphasize relinquishes objectivity and even embraces an awareness of our influence on our research and knowledge product. In this perspective, research is inventive, rather than scientific. Endres et al also emphasize that “critical approaches to fieldwork highlight the value of using it to access those everyday rhetorics that would otherwise go unnoticed, undocumented, and unexamined” (517). Although they don’t apply in situ rhetorical fieldwork to social media data collection, Yarimar Bonilla and Jonathan Rossa (2015) “examine the possibilities, the stakes, and the necessity of taking these forms of activism seriously while remaining attentive to the limits and possible pitfalls of engaging in what we describe as ‘hashtag ethnography’” (5). Although Twitter data analysis, even when conducted with participatory and critical frameworks will continue to present logistical and ethical challenges, Twitter data analysis does allow from the study of “rhetoric as it happens,” and a means to document and examine everyday rhetorics that might not surface in other digital or physical contexts.
  
## Arranging Nearly 2 Million Tweets

Many rhetoric and writing studies' examinations of social movements on Twitter focus on hashtag collections. At the time when I began collecting I wasn’t aware of any major hashtag campaigns related to gentrification; therefore, my initial intention was to collect data for an exploratory study. Rather than focusing on a particular hashtag or particular groups, I decided to collect using the keyword seed “gentrification.” Initially, I wanted to understand how people were communicating about gentrification on Twitter, and what kinds of visual media they might share and for what purposes. The results of this keyword search would include any tweets that used “gentrification” as a hashtag, username, or word within the tweet. I collected from February 2016 through the end of February 2018, allowing SFM to run for two full calendar years. This choice was influenced by personal experiences with urban change and reading news pieces, listening to everyday conversation, and observing plot lines in television and film. From my perspective, concerns about gentrification seemed to not only remain a salient topic over wide swaths of the public and media spheres but to be increasing in frequency. I also thought that the gentrification discussion might be relatively small on Twitter, a disparate simmer unlike the flurry of activity around a viral hashtag. My keyword search term “gentrification” would also limit my results since character-limited tweets would be encumbered by the lengthy and academic word. By collecting for two years, I hoped to amass a large dataset that would lend itself to comparative and individual case studies as well as for trend analysis across the corpora as a whole. Additionally, I chose to collect globally rather than focusing on a narrow location because recent studies in gentrification point to the need for more global data and perspectives on gentrification (Lees et al, 2015). After a year, I had collected over 600,000 tweets, and after two years I had almost tripled that number, resulting in a final dataset of 1,914,243. To understand what this large dataset contained, I first used computational methods to glean a thematic overview of the dataset as a whole and analyze viral trends.	

During the first year of data collection, I converted the JSON files of the Twitter data I’d collected so far into a spreadsheet form that mimicked the structure of the data Twitter afforded. Rows were delineated by tweet IDs and columns corresponded to the Twitter features I covered before like User Location, Tweet Text, and Coordinates. To get a grasp of important themes, as least those that were most frequently mentioned in tweets, I followed Kris Shaffer’s (2017) example in [“Mining Twitter data with R, TidyText, and TAGS”](https://pushpullfork.com/mining-twitter-data-tidy-text-tags/). Shaffer describes how researchers might use this suite that combines Google Twitter Archiving Data Sheets, or TAGS, with R and an R data structuring library to enable text mining and frequency analysis on Twitter datasets. Shaffer and his co-researcher Bill Fitzgerald used these tools to understand the way misinformation spreads on Twitter. Among other uses, these tools allow for word frequency charts and the parsing of bigrams, two-word associations that most frequently occur in a dataset. As Shaffer and Fitzgerald further point out, generating bigrams can be a starting point for other kinds of computational and traditional analysis, which generate different possibilities for interpretations and opportunities for comparison that contribute complexity to an analysis. Because Twitter data is rich in metadata, there is multidimensionally within each tweet entry. Shaffer and Fitzgerald ultimately focus in on the way in which urls are shared and disseminated across social networks of users to understand possible answers about how misinformation spreads on Twitter. I began with a similar though simpler approach to the dataset I collected, focusing on producing word frequencies and bigrams rather than networks. To protect users’ privacy, I followed Shaffer’s advice on using R to remove personal identifiers like handles and usernames as well as employing a standard list of stopwords. 

<div class="gallery">
{% include image.html image="/images/gentrification_wordcount.png" width="475px" height="380px" description="wordcount graph" %}
{% include image.html image="/images/gentrification_bigrams.png" width="475px" height="380px" description="bigram graph" %}
</div>
<figcaption>Figure 1: R analysis of tweet word and bigram count</figcaption>

In the initial word frequency visualization, issues of race and specific locations emerge. Generating bigrams, however, provides a more contextualized rendering of these themes. Instead of “people”, the bigram is “white people”; “anti” becomes “anti-gentrification”and “art” is “public art.” These richer descriptions might point to the prevalence of perceived agents involved in gentrification identified by users across the corpus as a whole or in areas where tweets are more prevalent. Because bigrams are word pairs, locations become clearer, for instance: Los Angeles, Boyle Heights, Boston’s Chinatown. This early partial sample analysis allowed me to focus subsequent research efforts and visualization practices around these emerging themes and locations in a way that human reading 600,000 tweets probably never would have. This kind of macroanalysis (Graham, Milligan, and Weingart, 2015; Jockers, 2013; Ramsay, 2011) can complement traditional methods of close reading and research; however, as Jockers notes:

> It is also problematic to draw conclusions about specific texts based on some general sense of the whole. This, however, is not the aim of macroanalysis. Rather, the macroscale perspective should inform our close readings of the individual texts by providing, if nothing else, a fuller sense of the literary-historical milieu in which a given book exists. It is through the application of both approaches that we reach a new and better-informed understanding of the primary materials. (p. 28). 

Although Jockers’ discipline is literature, rhetoric and writing studies can use this methodological idea of vacillating perspectives to explore our collection’s larger data environment, in my case the whole collection of tweets on gentrification, and then balance this macroscale perspective with closer examination of data subset(s). This vacillation between macro and micro scale, computer and human reading, provides new comparative possibilities between data scales. Yet this approach and a tool like R doesn’t quite completely resist the omniscient, distant view that feminist theories find problematic. By providing micro analysis that attends to “situated contexts and geographic locations” (D’Ignazio) and finding tools that afford more than computationally-driven visuals, we might create polyvocal, nuanced data storytelling that brings a critical awareness to how these differing scales contribute to knowledge making and how our methodologies might begin to talk back to positivist data paradigms.

<div class="next-container">
	<a class="next-page" href="{{ site.url }}/beyond-computation/">Next Page</a>
</div>
